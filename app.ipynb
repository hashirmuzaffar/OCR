{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON data\n",
    "with open('filtered-data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Inspect data structure\n",
    "print(json.dumps(data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "\n",
    "def crop_image_using_yolo(image_path, yolo_result, image_size):\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Parse yolo_result which is in the format 'x1,x2,y1,y2'\n",
    "        yolo_coords = list(map(int, yolo_result.split(',')))\n",
    "        # yolo_result example: \"0,1010,563,1266\"\n",
    "\n",
    "        # Extract the coordinates for cropping (left, upper, right, lower)\n",
    "        left = int((yolo_coords[0] / image_size[0]) * image_size[0])  # x1 -> left\n",
    "        right = int((yolo_coords[1] / image_size[0]) * image_size[0])  # x2 -> right\n",
    "        upper = int((yolo_coords[2] / image_size[1]) * image_size[1])  # y1 -> upper\n",
    "        lower = int((yolo_coords[3] / image_size[1]) * image_size[1])  # y2 -> lower\n",
    "\n",
    "        # Crop the image using the bounding box (left, upper, right, lower)\n",
    "        cropped_image = image.crop((left, upper, right, lower))\n",
    "        return cropped_image, (left, upper)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def process_images_from_json(json_file_path, image_folder):\n",
    "    # Load the JSON file\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Iterate through the documents in the JSON file\n",
    "    for doc_id, doc_info in data.items():\n",
    "        image_name = doc_info['path'] + '.jpeg'  # Assuming all images are in .jpeg format\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "        # Get the YOLO results and image size from the JSON\n",
    "        yolo_result = doc_info['yolo_result']\n",
    "        image_size = doc_info['size']\n",
    "\n",
    "        # Crop the image using the YOLO results\n",
    "        cropped_image, (crop_x1, crop_y1) = crop_image_using_yolo(image_path, yolo_result, image_size)\n",
    "\n",
    "        if cropped_image:\n",
    "            # Save or display the cropped image\n",
    "            cropped_image.show()  # Or save it: cropped_image.save(f'cropped_{image_name}')\n",
    "            print(f\"Processed and cropped image for document {doc_id}\")\n",
    "\n",
    "# Example usage:\n",
    "json_file_path = 'filtered-data.json'  # Path to the JSON file\n",
    "image_folder = 'Images'  # Folder where images are stored\n",
    "process_images_from_json(json_file_path, image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def assign_category(text):\n",
    "    \"\"\"\n",
    "    Assign category labels based on the extracted OCR text.\n",
    "    This is a simple rule-based function.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Example categories, can be expanded\n",
    "    if 'name' in text:\n",
    "        return 'Name'\n",
    "    elif 'dob' in text or 'birth' in text:\n",
    "        return 'Date of Birth'\n",
    "    elif 'number' in text or 'document' in text:\n",
    "        return 'Document Number'\n",
    "    elif 'expiry' in text:\n",
    "        return 'Expiry Date'\n",
    "    else:\n",
    "        return 'unknown'  # Template information\n",
    "\n",
    "def extract_ocr_data_and_assign_labels(data):\n",
    "    \"\"\"\n",
    "    Extract OCR text and assign category labels.\n",
    "    \"\"\"\n",
    "    extracted_data = []\n",
    "    \n",
    "    # Iterate through each document in the JSON\n",
    "    for doc_id, doc_info in data.items():\n",
    "        ocr_data = doc_info['ocr']  # OCR data section\n",
    "        \n",
    "        for text, coordinates in ocr_data.items():\n",
    "            category = assign_category(text)\n",
    "            \n",
    "            # Store extracted information (text, coordinates, category)\n",
    "            extracted_data.append({\n",
    "                'Document ID': doc_id,\n",
    "                'Text': text,\n",
    "                'Coordinates': coordinates,\n",
    "                'Category': category\n",
    "            })\n",
    "    \n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_and_assign_categories(json_file_path):\n",
    "    # Load the JSON file\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract data and assign category labels\n",
    "    extracted_data = extract_ocr_data_and_assign_labels(data)\n",
    "    \n",
    "    # Convert extracted data to a pandas DataFrame for easier manipulation\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ocr_extracted_data.csv\n"
     ]
    }
   ],
   "source": [
    "def save_data_to_csv(df, output_csv_path):\n",
    "    \"\"\"\n",
    "    Save the DataFrame containing extracted OCR text and category labels to a CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Data saved to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "json_file_path = 'filtered-data.json'  # Path to your JSON file\n",
    "output_csv_path = 'ocr_extracted_data.csv'  # Path where CSV will be saved\n",
    "\n",
    "# Process the JSON and get the DataFrame\n",
    "df = process_json_and_assign_categories(json_file_path)\n",
    "\n",
    "# Save to CSV\n",
    "save_data_to_csv(df, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to extracted_features.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "def load_json(json_file_path):\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Extract numeric features (width, height, coordinates) and categorize text\n",
    "def extract_features(data):\n",
    "    extracted_data = []\n",
    "    \n",
    "    for doc_id, doc_info in data.items():\n",
    "        image_path = doc_info.get('path')\n",
    "        document_type = doc_info.get('type')\n",
    "        ocr_data = doc_info.get('ocr', {})\n",
    "        image_size = doc_info.get('size', [1024, 661])  # Default size if missing\n",
    "        \n",
    "        # Iterate through the OCR data\n",
    "        for text, coords in ocr_data.items():\n",
    "            # Extract X and Y coordinates\n",
    "            x_coords = [coord['x'] for coord in coords]\n",
    "            y_coords = [coord['y'] for coord in coords]\n",
    "            \n",
    "            # Calculate width, height, relative length, and slope\n",
    "            width = max(x_coords) - min(x_coords)\n",
    "            height = max(y_coords) - min(y_coords)\n",
    "            relative_length = width / height if height != 0 else 0\n",
    "            slope = (y_coords[-1] - y_coords[0]) / (x_coords[-1] - x_coords[0]) if (x_coords[-1] - x_coords[0]) != 0 else 0\n",
    "            \n",
    "            # Normalize coordinates between 0 and 1\n",
    "            normalized_coords = [(x / image_size[0], y / image_size[1]) for x, y in zip(x_coords, y_coords)]\n",
    "            \n",
    "            # Assign category to the text\n",
    "            category = assign_category(text, doc_info.get('llm', {}))  # Use LLM response to assist classification\n",
    "            \n",
    "            # Store the extracted data\n",
    "            extracted_data.append({\n",
    "                'Document ID': doc_id,\n",
    "                'Image Path': image_path,\n",
    "                'Document Type': document_type,\n",
    "                'Text': text,\n",
    "                'X Coordinates': x_coords,\n",
    "                'Y Coordinates': y_coords,\n",
    "                'Width': width,\n",
    "                'Height': height,\n",
    "                'Relative Length': relative_length,\n",
    "                'Slope': slope,\n",
    "                'Normalized Coordinates': normalized_coords,\n",
    "                'Category': category\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(extracted_data)\n",
    "\n",
    "# Function to categorize text based on its content\n",
    "def assign_category(text, llm_response):\n",
    "    text = text.lower()\n",
    "    llm_text = llm_response.get('response', {}).get('text', '').lower()\n",
    "    \n",
    "    # Rule-based classification using LLM and OCR content\n",
    "    if 'name' in text or 'eesnimi' in text or 'given' in text:\n",
    "        return 'Name'\n",
    "    elif 'surname' in text or 'perekonnanimi' in text:\n",
    "        return 'Surname'\n",
    "    elif 'dob' in text or 'birth' in text or 's√ºnniaeg' in text:\n",
    "        return 'Date of Birth'\n",
    "    elif 'document' in text or 'number' in text:\n",
    "        return 'Document Number'\n",
    "    elif 'expiry' in text or 'kehtiv' in text:\n",
    "        return 'Expiry Date'\n",
    "    elif text in llm_text:\n",
    "        return 'User Data'  # Data that is part of the user-specific information\n",
    "    else:\n",
    "        return 'unknown'  # Template/static information\n",
    "\n",
    "# Save the extracted features and categories to a CSV file\n",
    "def save_to_csv(df, output_file):\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    json_file_path = 'filtered-data.json'  # Replace with your actual path\n",
    "    output_csv_path = 'extracted_features.csv'  # Path to save the CSV file\n",
    "    \n",
    "    # Load and process the JSON data\n",
    "    json_data = load_json(json_file_path)\n",
    "    features_df = extract_features(json_data)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    save_to_csv(features_df, output_csv_path)\n",
    "\n",
    "# Run the process\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
